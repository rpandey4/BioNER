{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'CDR_Data/BC5CDR-disease/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsv(path):\n",
    "    result = []\n",
    "    with open(path) as fp:\n",
    "        for sent in fp.read().split('\\n\\n'):\n",
    "            sent_toks = []\n",
    "            for tok in sent.strip().split('\\n'):\n",
    "                tok = tok.strip()\n",
    "                if len(tok) == 0:\n",
    "                    continue\n",
    "                tok, tag = tok.split('\\t')\n",
    "                sent_toks.append((tok, tag))\n",
    "            result.append(sent_toks)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = read_tsv(os.path.join(DATA_PATH, 'train.tsv'))\n",
    "valid_sents = read_tsv(os.path.join(DATA_PATH, 'devel.tsv'))\n",
    "test_sents = read_tsv(os.path.join(DATA_PATH, 'test.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "Next, define some features. In this example we use word identity, word suffix, and word shape; also, some information from nearby words is used.\n",
    "\n",
    "This makes a simple baseline, but you certainly can add and remove some features to get (much?) better results - experiment with it.\n",
    "\n",
    "sklearn-crfsuite (and python-crfsuite) supports several feature formats; here we use feature dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_map(data, token_or_tag, start=0):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set([tok for sent in data for tok, tag in sent]))\n",
    "    else:\n",
    "        vocab = list(set([tag for sent in data for tok, tag in sent]))\n",
    "    idx2tok = {idx + start:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx + start for  idx, tok in enumerate(vocab)}\n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "corpus = train_sents + valid_sents + test_sents\n",
    "token2idx, idx2token = get_dict_map(corpus, 'token', start=1)\n",
    "tag2idx, idx2tag = get_dict_map(corpus, 'tag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what token2idx and tag2idx extracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Vocabulary Size: {}'.format(len(idx2token)))\n",
    "print('Label Info: ', tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(s, key2idx):\n",
    "    return list([key2idx[tok] for tok, tag in s])\n",
    "\n",
    "def sent2labels(s, key2idx):\n",
    "    return list([key2idx[tag] for tok, tag in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s, token2idx) for s in train_sents]\n",
    "y_train = [sent2labels(s, tag2idx) for s in train_sents]\n",
    "\n",
    "X_valid = [sent2features(s, token2idx) for s in valid_sents]\n",
    "y_valid = [sent2labels(s, tag2idx) for s in valid_sents]\n",
    "\n",
    "X_test = [sent2features(s, token2idx) for s in test_sents]\n",
    "y_test = [sent2labels(s, tag2idx) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tokens, tags, maxlen=None):\n",
    "    if maxlen is None:\n",
    "        maxlen = max([len(s) for s in tokens])\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='pre', value=0)\n",
    "    #Pad Tags (y var) and convert it into one hot encoding\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value=tag2idx['O'])\n",
    "    n_tags = len(tag2idx)\n",
    "    pad_tags = np.array([to_categorical(i, num_classes=n_tags) for i in pad_tags])\n",
    "    return pad_tokens, pad_tags, maxlen\n",
    "\n",
    "X_train_pad, y_train_pad, maxlen = preprocess(X_train, y_train)\n",
    "X_valid_pad, y_valid_pad, _ = preprocess(X_valid, y_valid, maxlen)\n",
    "X_test_pad, y_test_pad, _ = preprocess(X_test, y_test, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_pad.shape, y_train_pad.shape)\n",
    "print(X_valid_pad.shape, y_valid_pad.shape)\n",
    "print(X_test_pad.shape, y_test_pad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "To see all possible CRF parameters check its docstring. \n",
    "Here we are useing L-BFGS training algorithm (it is default) with Elastic Net (L1 + L2) regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(token2idx) + 1\n",
    "output_dim = 64\n",
    "input_length = X_train_pad.shape[1]\n",
    "n_tags = len(tag2idx)\n",
    "\n",
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "    # Add Embedding layer\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "    # Add bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "    # Add LSTM\n",
    "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "    # Add timeDistributed Layer\n",
    "    model.add(TimeDistributed(Dense(n_tags, activation=\"relu\")))\n",
    "    #Optimiser \n",
    "    # adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def train_model(X, y, model):\n",
    "    loss = list()\n",
    "    for i in range(25):\n",
    "        # fit model for one epoch on this sequence\n",
    "        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.2)\n",
    "        loss.append(hist.history['loss'][0])\n",
    "    return loss\n",
    "# construct the model\n",
    "model_bilstm_lstm = get_bilstm_lstm_model()\n",
    "# plot_model(model_bilstm_lstm)\n",
    "results['with_add_lstm'] = train_model(X_train_pad, np.array(y_train_pad), model_bilstm_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_valid)\n",
    "metrics.flat_f1_score(y_valid, y_pred, average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_valid, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
